{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8148c08",
   "metadata": {},
   "source": [
    "### MF731 HW2 Part1\n",
    "#### Edited By Xuyang Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08211737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf98d0",
   "metadata": {},
   "source": [
    "#### 1. VaR for a Portfolio of Microsoft, Apple and Google Stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7523cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(a)\n",
    "lamda = 0.97\n",
    "theta = 0.97\n",
    "data = pd.read_excel('StockData.xlsx',index_col=0)\n",
    "logret = np.log(data/data.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324aca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mu\n",
    "mu = np.zeros([len(logret),3])\n",
    "for i in range(1,len(logret)):\n",
    "    mu[i,:] = lamda * mu[i-1,:] + (1-lamda) * logret.iloc[i,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2527248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00263687, 0.00238145, 0.00312769])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[-1] # mu for 8/31/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5091bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the newest covariance matrix\n",
    "sigma = np.mat([[0,0,0],[0,0,0],[0,0,0]])\n",
    "for i in range(1,len(logret)+1):\n",
    "    sigma = theta * sigma + (1-theta) * ( np.mat(logret.iloc[i-1,:].values)-np.mat(mu[i-1,:]) ).T * ( np.mat(logret.iloc[i-1,:].values)-np.mat(mu[i-1,:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d11c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9.47092473e-05, 8.21428718e-05, 5.37927754e-05],\n",
       "        [8.21428718e-05, 1.58101963e-04, 7.23027640e-05],\n",
       "        [5.37927754e-05, 7.23027640e-05, 1.02648243e-04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma # sigma matrix for 8/31/21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e65732",
   "metadata": {},
   "source": [
    " ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d28a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(b)\n",
    "alpha = 0.95\n",
    "m_port = 2.269/(2.269+2.510+1.940)\n",
    "a_port = 2.510/(2.269+2.510+1.940)\n",
    "g_port = 1.940/(2.269+2.510+1.940)\n",
    "\n",
    "theta_ar = np.array([m_port,a_port,g_port])\n",
    "theta_mat = np.mat([m_port,a_port,g_port])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c06b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For empirical distribution\n",
    "emp_port = pd.DataFrame()\n",
    "emp_port[\"Full\"] = -np.dot((np.exp(logret)-1),theta_ar)\n",
    "emp_port[\"Lin\"] = -np.dot(logret,theta_ar)\n",
    "emp_port[\"Sec\"] = emp_port[\"Lin\"] - 0.5*np.dot((logret**2),theta_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19735802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VaR of emprical full loss is 27862.93997656743\n",
      "The VaR of emprical linear loss is 28262.53177239395\n",
      "The VaR of emprical quadric loss is 27859.09556465448\n"
     ]
    }
   ],
   "source": [
    "print(\"The VaR of emprical full loss is\",emp_port.sort_values(\"Full\")[\"Full\"].quantile(0.95)* 1000000  )\n",
    "print(\"The VaR of emprical linear loss is\",emp_port.sort_values(\"Lin\")[\"Lin\"].quantile(0.95)* 1000000 )\n",
    "print(\"The VaR of emprical quadric loss is\",emp_port.sort_values(\"Sec\")[\"Sec\"].quantile(0.95)* 1000000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59155783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simulation\n",
    "# for EWMA X\n",
    "def loss_VaR(mu,sigma,losstype):\n",
    "    loss = []\n",
    "    for i in range(10000):\n",
    "        X = np.random.multivariate_normal(mu,sigma)\n",
    "        if losstype == 'Full':\n",
    "            Full_loss =  - np.dot((np.exp(X)-1),theta_ar) * 1000000\n",
    "            loss.append(Full_loss)\n",
    "        elif losstype == 'Linear':\n",
    "            linear_loss = -np.dot(X , theta_ar) * 1000000\n",
    "            loss.append(linear_loss)\n",
    "        elif losstype == 'Second':\n",
    "            second_loss = -np.dot(X + 0.5 * X**2 , theta_ar) * 1000000\n",
    "            loss.append(second_loss)\n",
    "    \n",
    "    VaR = -(-pd.Series(loss).quantile(alpha) )\n",
    "    if losstype == 'Linear':\n",
    "        VaR = (((theta_mat * sigma * theta_mat.T)[0,0]**(1/2) * norm.ppf(alpha)) - np.dot(mu,theta_ar) ) * 1000000\n",
    "    return loss,VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc37274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_loss_Full, sm_VaR_Full = loss_VaR(mu[-1],sigma,'Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf380f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_loss_linear, sm_VaR_linear = loss_VaR(mu[-1],sigma,'Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ed546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_loss_second, sm_VaR_second = loss_VaR(mu[-1],sigma,'Second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63ab085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VaR of simulation full loss is 12824.363958321215\n",
      "The VaR of simulation linear loss is 12767.46428767112\n",
      "The VaR of simulation quadric loss is 12142.339340669829\n"
     ]
    }
   ],
   "source": [
    "print(\"The VaR of simulation full loss is\",sm_VaR_Full)\n",
    "print(\"The VaR of simulation linear loss is\",sm_VaR_linear)\n",
    "print(\"The VaR of simulation quadric loss is\",sm_VaR_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126b582",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2368ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For standard estimate\n",
    "stand_mu = logret.mean().values\n",
    "stand_sigma = logret.cov().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7092532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The VaR of simulation full loss is 30804.142089729598\n",
      "The VaR of simulation linear loss is 30953.022771690412\n",
      "The VaR of simulation quadric loss is 30368.61355517262\n"
     ]
    }
   ],
   "source": [
    "sm_loss_Full, sm_VaR_Full = loss_VaR(stand_mu,stand_sigma,'Full')\n",
    "sm_loss_linear, sm_VaR_linear = loss_VaR(stand_mu,stand_sigma,'Linear')\n",
    "sm_loss_second, sm_VaR_second = loss_VaR(stand_mu,stand_sigma,'Second')\n",
    "print(\"The VaR of simulation full loss is\",sm_VaR_Full)\n",
    "print(\"The VaR of simulation linear loss is\",sm_VaR_linear)\n",
    "print(\"The VaR of simulation quadric loss is\",sm_VaR_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282654d2",
   "metadata": {},
   "source": [
    "From the result above we can see that, the empirical VaR is around 27000, normal VaR using EWMA is about 13000, and normal VaR using standard estimator is about 30000. The reason why EWMA is less"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d70a2",
   "metadata": {},
   "source": [
    "#### 2.VaR and Time Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a10b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)\n",
    "alpha = 0.95\n",
    "t = 0\n",
    "K = 10\n",
    "delta = 1/252\n",
    "T = 0.292\n",
    "S0 = 152.51\n",
    "k = 170\n",
    "strike = 170\n",
    "r = 0.00119\n",
    "sigma = 0.4907\n",
    "u = 16.91/100\n",
    "N = 4000\n",
    "\n",
    "def BS(t,St,K):\n",
    "    # BS model, input t, St and K, return put price and Greek delta\n",
    "    d1 = 1/(sigma * ((T-t)**0.5)) * (np.log(St/K) + (r + 0.5 * sigma**2) * (T-t))\n",
    "    d2 = d1 - sigma * (T-t)**0.5\n",
    "    p = St * (norm.cdf(d1)-1) + K * np.exp(-r * (T-t)) * (1-norm.cdf(d2))\n",
    "    delta_greek = norm.cdf(d1) - 1\n",
    "    #gamma = norm.pdf(d1)/(St * sigma * (T-t)**0.5)\n",
    "    #theta = -sigma/(2 * (T-t)**0.5) * St * norm.pdf(d1) + K * r * np.exp(-r * (T-t)) * (1-norm.cdf(d2))\n",
    "    return p,delta_greek\n",
    "\n",
    "P0, h0 = BS(t,St,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dad4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss1day(N):\n",
    "    # this funciton is not used\n",
    "    losslst = []\n",
    "    for i in range(N):\n",
    "        \n",
    "        V0 = h0 * S0 + 0 - P0\n",
    "        S1 = S0 * np.exp((u-1/2 * sigma**2)*delta + sigma*(delta)**0.5 * np.random.normal())\n",
    "        P1,h1 = BS(t+delta,S1,strike)\n",
    "        V1 = h0 * S1 +0 -P1\n",
    "        Loss = V0-V1\n",
    "        losslst.append(Loss)\n",
    "        \n",
    "    return losslst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ba7008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss10day(N,days):\n",
    "    losslst = []\n",
    "    for i in range(N):\n",
    "        daylosslst = []\n",
    "        Sk0 = S0\n",
    "        Pk0,hk0 = BS(t,Sk0,strike)\n",
    "        Yk0 = 0\n",
    "        for j in range(days):\n",
    "            Vk0 = hk0 * Sk0 + Yk0 - Pk0\n",
    "            Skt = Sk0 * np.exp((u-1/2 * sigma**2)*delta + sigma*(delta)**0.5 * np.random.normal())\n",
    "            Pkt,hkt = BS(t+(j+1)*delta,Skt,strike)\n",
    "            Vkt = hk0 * Skt + Yk0 * np.exp(delta * r) - Pkt\n",
    "            Loss = -(Vkt - Vk0)\n",
    "\n",
    "            Ykt = Yk0 - (hkt - hk0) * Sk0\n",
    "            Yk0 = Ykt\n",
    "            Vk0 = Vkt\n",
    "            hk0 = hkt\n",
    "            Sk0 = Skt\n",
    "            Pk0 = Pkt\n",
    "            daylosslst.append(Loss)\n",
    "        dayloss = sum(daylosslst)\n",
    "        losslst.append(dayloss)\n",
    "    return losslst          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4607e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onedayloss = Loss10day(40000,1)\n",
    "onedayVaR = pd.Series(onedayloss).quantile(0.95) * 100\n",
    "tendayloss = Loss10day(40000,10)\n",
    "tendayVaR = pd.Series(tendayloss).quantile(0.95) * 100\n",
    "direct = onedayVaR * 10**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d160030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 day VaR is about:  30.529933682155015\n",
      "the 10 day VaR is about:  89.20855753972728\n",
      "the result of one day VaR times Sqrt(10):  96.54412724950096\n"
     ]
    }
   ],
   "source": [
    "print(\"the 1 day VaR is about: \",onedayVaR)\n",
    "print(\"the 10 day VaR is about: \", tendayVaR)\n",
    "print(\"the result of one day VaR times Sqrt(10): \", direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bcfd3",
   "metadata": {},
   "source": [
    "#### 3.  Backtesting VaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87d819d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP = pd.read_csv('SP_Prices.csv',index_col=0,header=None)\n",
    "SPret = np.log(SP/SP.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43547205",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.95\n",
    "beta = 0.05\n",
    "theta = 0.97\n",
    "lamda = 0.97\n",
    "M = 1010\n",
    "N = len(SPret)\n",
    "\n",
    "# For empirical distribution\n",
    "Loss = 1 - np.exp(SPret.iloc[:,0])\n",
    "\n",
    "VaR_emp = []\n",
    "exc_emp = 0\n",
    "for i in range(N-M):\n",
    "    VaR = np.quantile(Loss[i:i+M] , alpha)\n",
    "    VaR_emp.append(VaR)\n",
    "    if Loss.iloc[i+M]>VaR_emp[-1]:\n",
    "        exc_emp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f55ac30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "494c365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EWMA updating\n",
    "mu0 = np.mean(SPret.iloc[0:M-1,0])\n",
    "sig0 = np.var(SPret.iloc[0:M-1,0])**0.5\n",
    "VaR_EWMA = []\n",
    "exc_EWMA = 0\n",
    "\n",
    "for i in range(1,N-M):\n",
    "    mu0 = lamda * mu0 + (1-lamda) * SPret.iloc[i+M-1,0]\n",
    "    sig0 = (theta * sig0**2 + (1-theta) * (SPret.iloc[i+M-1,0]-mu0)**2) **0.5\n",
    "    VaR = -(np.exp(mu0+sig0 *norm.ppf(1-alpha))-1)\n",
    "    VaR_EWMA.append(VaR)\n",
    "    if Loss.iloc[i+M] > VaR_EWMA[-1]:\n",
    "        exc_EWMA += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e10cd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc_EWMA # in class we got 79, I think that might because we keep the different decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33371963",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = N-M\n",
    "CI_low = diff * (1-alpha) - norm.ppf(1-beta/2) * np.sqrt(diff*alpha*(1-alpha))\n",
    "CI_high = diff * (1-alpha) + norm.ppf(1-beta/2) * np.sqrt(diff*alpha*(1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e574d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.40000000000006"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff * (1-alpha) # For Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa195ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58.81194118269656, 91.98805881730357)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CI_low,CI_high # For CI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
